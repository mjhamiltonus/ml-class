{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B Run: https://app.wandb.ai/qualcomm/imdb-dec3/runs/fozfr5c2\n",
      "Call `%%wandb` in the cell containing your training loop to display live results.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<keras.layers.embeddings.Embedding at 0x7fec5cc761d0>,\n",
       " <keras.layers.wrappers.Bidirectional at 0x7fec5ccec588>,\n",
       " <keras.layers.core.Dense at 0x7fec5cc8f898>]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Bidirectional\n",
    "from keras.layers import Embedding, LSTM\n",
    "from keras.layers import Conv1D, Flatten\n",
    "from keras.datasets import imdb\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "import imdb\n",
    "import numpy as np\n",
    "from keras.preprocessing import text\n",
    "\n",
    "wandb.init()\n",
    "config = wandb.config\n",
    "\n",
    "\n",
    "# set parameters:\n",
    "config.vocab_size = 1500      # 300\n",
    "config.maxlen = 200           # 200.  Mode is about 180\n",
    "config.batch_size = 32\n",
    "config.embedding_dims = 50   #  20\n",
    "config.filters = 250\n",
    "config.kernel_size = 3\n",
    "config.hidden_dims = 100\n",
    "config.epochs = 10\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_imdb()\n",
    "\n",
    "tokenizer = text.Tokenizer(num_words=config.vocab_size)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "from keras.models import load_model\n",
    "model = load_model(\"/home/mjh/ml-class/lstm/imdb-classifier/wandb/run-20181204_155224-q0l6ob4a/model-best.h5\")\n",
    "model.layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[58, 461, 298, 11, 13, 3, 84, 17, 9, 13, 21]]\n",
      "['my friend said this was a great movie it was not']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.69879717]], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myQuote=[\"my Friend said this was a GREAT movie. it was not\"]\n",
    "myInput=tokenizer.texts_to_sequences(myQuote)\n",
    "print(\"{:}\".format(myInput))\n",
    "print(\"{:}\".format(tokenizer.sequences_to_texts(myInput)))\n",
    "myInput= sequence.pad_sequences(myInput, maxlen=config.maxlen)\n",
    "model.predict(myInput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "about to predict\n"
     ]
    }
   ],
   "source": [
    "# Find the errors and worst errors\n",
    "myTraining = tokenizer.texts_to_sequences(X_train)\n",
    "myTraining = sequence.pad_sequences(myTraining, maxlen=config.maxlen)\n",
    "print(\"about to predict\")\n",
    "preds = model.predict(myTraining)\n",
    "print(\"done predicting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iWorst = np.argmax(np.abs(preds-y_train))\n",
    "print(\"{:}\".format(X_train[iWorst]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
